{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Crello analysis\n",
    "\n",
    "This notebook qualitatively analyzes learned models in crello-document dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import itertools\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "sys.path.append('../src/canvas-vae')\n",
    "\n",
    "from canvasvae.models.vae import VAE\n",
    "from canvasvae.data import DataSpec\n",
    "from canvasvae.helpers.svg import SVGBuilder\n",
    "from canvasvae.helpers.retrieve import ImageRetriever\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_name = 'crello-document'\n",
    "dataspec = DataSpec(dataset_name, f\"../data/{dataset_name}\", batch_size=2)\n",
    "train_dataset = dataspec.make_dataset('train', shuffle=True)\n",
    "test_dataset = dataspec.make_dataset('test', shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load learned models. Edit the configuration tuples to match parameters and the job/trial ids."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_model(\n",
    "    decoder_type,\n",
    "    block_type,\n",
    "    num_blocks,\n",
    "    latent_dim,\n",
    "    job_id,\n",
    "    best_or_final='final',\n",
    "):\n",
    "    model = VAE(\n",
    "        dataspec.make_input_columns(),\n",
    "        decoder_type=decoder_type,\n",
    "        latent_dim=latent_dim,\n",
    "        num_blocks=num_blocks,\n",
    "        block_type=block_type,\n",
    "    )\n",
    "    model.compile(optimizer='adam')\n",
    "    model.load_weights(f\"tmp/canvasvae/jobs/{job_id}/checkpoints/{best_or_final}.ckpt\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Uncomment the following with appropriate config and job id.\n",
    "models = {\n",
    "    f\"{args[0]}_{args[1]}{args[2]}\": load_model(*args) for args in [\n",
    "#         ('autoregressive', 'lstm', 1, 512, '20210818223504'),\n",
    "#         ('autoregressive', 'deepsvg', 1, 512, '20210818223504'),\n",
    "#         ('autoregressive', 'deepsvg', 4, 512, '20210818223504'),\n",
    "#         ('oneshot', 'lstm', 1, 512, '20210818223504'),\n",
    "#         ('oneshot', 'deepsvg', 1, 512, '20210818223504'),\n",
    "#         ('oneshot', 'deepsvg', 4, 512, '20210818223504'),\n",
    "    ]\n",
    "}\n",
    "models"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build the image retrieval subsystem for visualization. This can take long (~15min) depending on the available CPU/GPUs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "encoder = tf.keras.models.load_model('../data/pixelvae/encoder')\n",
    "\n",
    "train_image_db = ImageRetriever(\n",
    "    dataset_path='../data/crello-image/train*',\n",
    "    cache_dir='../tmp/retriever/train_images',\n",
    ")\n",
    "%time train_image_db.build(encoder)\n",
    "\n",
    "test_image_db = ImageRetriever(\n",
    "    dataset_path='../data/crello-image/test*',\n",
    "    cache_dir='../tmp/retriever/test_images',\n",
    ")\n",
    "%time test_image_db.build(encoder)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prepare SVG document builder for visualization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "builder0 = SVGBuilder(\n",
    "    max_width=128, \n",
    "    max_height=192,\n",
    "    key='type',\n",
    "    preprocessor=dataspec.preprocessor,\n",
    ")\n",
    "builder1 = SVGBuilder(\n",
    "    max_width=128, \n",
    "    max_height=192,\n",
    "    key='color',\n",
    "    preprocessor=dataspec.preprocessor,\n",
    "    image_db=train_image_db,\n",
    "    render_text=True,\n",
    ")\n",
    "builder2 = SVGBuilder(\n",
    "    max_width=128, \n",
    "    max_height=192,\n",
    "    key='color',\n",
    "    preprocessor=dataspec.preprocessor,\n",
    "    image_db=test_image_db,\n",
    "    render_text=True,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reconstruction and sampling\n",
    "\n",
    "The following visualizes reconstruction with stochastic sampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return itertools.zip_longest(*args, fillvalue=fillvalue)\n",
    "\n",
    "\n",
    "def visualize_reconstruction(model, example, dataspec, input_builders, output_builders):\n",
    "    svgs = []\n",
    "    for builder in input_builders:\n",
    "        svgs.append(list(map(builder, dataspec.unbatch(example))))\n",
    "    for i in range(3):\n",
    "        prediction = model(example, sampling=(i > 0))\n",
    "        for builder in output_builders:\n",
    "            svgs.append(list(map(builder, dataspec.unbatch(prediction))))\n",
    "    return [list(grouper(row, len(input_builders))) for row in zip(*svgs)] \n",
    "\n",
    "\n",
    "example = next(iter(test_dataset.take(1)))\n",
    "svgs = {}\n",
    "for key, model in models.items():\n",
    "    print(key)\n",
    "    svgs[key] = visualize_reconstruction(model, example, dataspec, [builder0, builder2], [builder0, builder1])\n",
    "    for row in svgs[key]:\n",
    "        display(HTML('<div>%s</div>' % ' '.join(itertools.chain.from_iterable(row))))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Interpolation\n",
    "\n",
    "Show interpolation between two samples."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def visualize_interpolation(model, example1, example2, dataspec, input_builders, output_builders, num_samples=8):\n",
    "    z1 = model.encoder(example1, sampling=False)\n",
    "    z2 = model.encoder(example2, sampling=False)\n",
    "    cols = []\n",
    "    for builder in input_builders:\n",
    "        cols.append(list(map(builder, dataspec.unbatch(example1))))\n",
    "    for u in np.linspace(0, 1, num_samples):\n",
    "        z = z1 * (1 - u) + z2 * u\n",
    "        prediction = model.decoder(z)\n",
    "        for builder in output_builders:\n",
    "            cols.append(list(map(builder, dataspec.unbatch(prediction))))\n",
    "    for builder in input_builders:\n",
    "        cols.append(list(map(builder, dataspec.unbatch(example2))))\n",
    "        \n",
    "    return [list(grouper(row, len(input_builders))) for row in zip(*cols)]\n",
    "\n",
    "\n",
    "itr = iter(test_dataset.take(2))\n",
    "example1, example2 = next(itr), next(itr)\n",
    "\n",
    "layouts, previews = {}, {}\n",
    "for key, model in models.items():\n",
    "    print(key)\n",
    "    layouts[key] = visualize_interpolation(model, example1, example2, dataspec, [builder0], [builder0])\n",
    "    previews[key] = visualize_interpolation(model, example1, example2, dataspec, [builder2], [builder1])\n",
    "    for row1, row2 in zip(layouts[key], previews[key]):\n",
    "        display(HTML('<div>%s</div>' % ' '.join(itertools.chain.from_iterable(row1))))\n",
    "        display(HTML('<div>%s</div>' % ' '.join(itertools.chain.from_iterable(row2))))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random generation\n",
    "\n",
    "Show randomly generated documents."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def generate_random(model, builders, batch_size=16):\n",
    "    z = tf.random.normal(shape=(batch_size, model.decoder.latent_dim))\n",
    "    prediction = model.decoder(z)\n",
    "    svgs = []\n",
    "    for item in dataspec.unbatch(prediction):\n",
    "        svgs.append(tuple(builder(item) for builder in builders))\n",
    "    return svgs\n",
    "\n",
    "for key, model in models.items():\n",
    "    print(key)\n",
    "    generated = generate_random(model, [builder0, builder1])\n",
    "    display(HTML('<div>%s</div>' % ' '.join(itertools.chain.from_iterable(generated))))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}