{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crello analysis\n",
    "\n",
    "This notebook qualitatively analyzes learned models in crello-document dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "sys.path.append('../src/canvas-vae')\n",
    "\n",
    "from canvasvae.models.vae import VAE\n",
    "from canvasvae.data import DataSpec\n",
    "from canvasvae.helpers.svg import SVGBuilder\n",
    "from canvasvae.helpers.retrieve import ImageRetriever\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'crello-document'\n",
    "dataspec = DataSpec(dataset_name, f\"../data/{dataset_name}\", batch_size=2)\n",
    "train_dataset = dataspec.make_dataset('train', shuffle=True)\n",
    "test_dataset = dataspec.make_dataset('test', shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load learned models. Edit the job id list to choose which experiment to inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(job_id, best_or_final='final'):\n",
    "    job_dir = f\"../tmp/jobs/canvasvae/{job_id}\"\n",
    "    with open(os.path.join(job_dir, 'test_results.json'), 'r') as f:\n",
    "        results = json.load(f)\n",
    "        \n",
    "    name = f\"{results['decoder_type']}_{results['block_type']}{results['num_blocks']}\"\n",
    "    model = VAE(\n",
    "        dataspec.make_input_columns(),\n",
    "        decoder_type=results['decoder_type'],\n",
    "        latent_dim=results['latent_dim'],\n",
    "        num_blocks=results['num_blocks'],\n",
    "        block_type=results['block_type'],\n",
    "    )\n",
    "    model.compile(optimizer='adam')\n",
    "    model.load_weights(f\"{job_dir}/checkpoints/{best_or_final}.ckpt\")\n",
    "    return name, model\n",
    "\n",
    "\n",
    "# Fill in appropriate job ids.\n",
    "job_ids = ['20210827035436']\n",
    "models = {name: model for name, model in map(load_model, job_ids)}\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the image retrieval subsystem for visualization. This can take long (~15min) depending on the available CPU/GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.models.load_model('../data/pixelvae/encoder')\n",
    "\n",
    "train_image_db = ImageRetriever(\n",
    "    dataset_path='../data/crello-image/train*',\n",
    "    cache_dir='../tmp/retriever/train_images',\n",
    ")\n",
    "%time train_image_db.build(encoder)\n",
    "\n",
    "test_image_db = ImageRetriever(\n",
    "    dataset_path='../data/crello-image/test*',\n",
    "    cache_dir='../tmp/retriever/test_images',\n",
    ")\n",
    "%time test_image_db.build(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare SVG document builders for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder0 = SVGBuilder(\n",
    "    max_width=128, \n",
    "    max_height=192,\n",
    "    key='type',\n",
    "    preprocessor=dataspec.preprocessor,\n",
    ")\n",
    "builder1 = SVGBuilder(\n",
    "    max_width=128, \n",
    "    max_height=192,\n",
    "    key='color',\n",
    "    preprocessor=dataspec.preprocessor,\n",
    "    image_db=train_image_db,\n",
    "    render_text=True,\n",
    ")\n",
    "builder2 = SVGBuilder(\n",
    "    max_width=128, \n",
    "    max_height=192,\n",
    "    key='color',\n",
    "    preprocessor=dataspec.preprocessor,\n",
    "    image_db=test_image_db,\n",
    "    render_text=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction and sampling\n",
    "\n",
    "The following visualizes reconstruction with stochastic sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return itertools.zip_longest(*args, fillvalue=fillvalue)\n",
    "\n",
    "\n",
    "def visualize_reconstruction(model, example, dataspec, input_builders, output_builders):\n",
    "    svgs = []\n",
    "    for builder in input_builders:\n",
    "        svgs.append(list(map(builder, dataspec.unbatch(example))))\n",
    "    for i in range(3):\n",
    "        prediction = model(example, sampling=(i > 0))\n",
    "        for builder in output_builders:\n",
    "            svgs.append(list(map(builder, dataspec.unbatch(prediction))))\n",
    "    return [list(grouper(row, len(input_builders))) for row in zip(*svgs)] \n",
    "\n",
    "\n",
    "example = next(iter(test_dataset.take(1)))\n",
    "svgs = {}\n",
    "for key, model in models.items():\n",
    "    print(key)\n",
    "    svgs[key] = visualize_reconstruction(model, example, dataspec, [builder0, builder2], [builder0, builder1])\n",
    "    for row in svgs[key]:\n",
    "        display(HTML('<div>%s</div>' % ' '.join(itertools.chain.from_iterable(row))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation\n",
    "\n",
    "Show interpolation between two samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_interpolation(model, example1, example2, dataspec, input_builders, output_builders, num_samples=8):\n",
    "    z1 = model.encoder(example1, sampling=False)\n",
    "    z2 = model.encoder(example2, sampling=False)\n",
    "    cols = []\n",
    "    for builder in input_builders:\n",
    "        cols.append(list(map(builder, dataspec.unbatch(example1))))\n",
    "    for u in tf.cast(tf.linspace(0, 1, num_samples), tf.float32):\n",
    "        z = z1 * (1 - u) + z2 * u\n",
    "        prediction = model.decoder(z)\n",
    "        for builder in output_builders:\n",
    "            cols.append(list(map(builder, dataspec.unbatch(prediction))))\n",
    "    for builder in input_builders:\n",
    "        cols.append(list(map(builder, dataspec.unbatch(example2))))\n",
    "        \n",
    "    return [list(grouper(row, len(input_builders))) for row in zip(*cols)]\n",
    "\n",
    "\n",
    "itr = iter(test_dataset.take(2))\n",
    "example1, example2 = next(itr), next(itr)\n",
    "\n",
    "layouts, previews = {}, {}\n",
    "for key, model in models.items():\n",
    "    print(key)\n",
    "    layouts[key] = visualize_interpolation(model, example1, example2, dataspec, [builder0], [builder0])\n",
    "    previews[key] = visualize_interpolation(model, example1, example2, dataspec, [builder2], [builder1])\n",
    "    for row1, row2 in zip(layouts[key], previews[key]):\n",
    "        display(HTML('<div>%s</div>' % ' '.join(itertools.chain.from_iterable(row1))))\n",
    "        display(HTML('<div>%s</div>' % ' '.join(itertools.chain.from_iterable(row2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random generation\n",
    "\n",
    "Show randomly generated documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random(model, builders, batch_size=16):\n",
    "    z = tf.random.normal(shape=(batch_size, model.decoder.latent_dim))\n",
    "    prediction = model.decoder(z)\n",
    "    svgs = []\n",
    "    for item in dataspec.unbatch(prediction):\n",
    "        svgs.append(tuple(builder(item) for builder in builders))\n",
    "    return svgs\n",
    "\n",
    "for key, model in models.items():\n",
    "    print(key)\n",
    "    generated = generate_random(model, [builder0, builder1])\n",
    "    display(HTML('<div>%s</div>' % ' '.join(itertools.chain.from_iterable(generated))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m78",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m78"
  },
  "kernelspec": {
   "display_name": "canvas-vae",
   "language": "python",
   "name": "canvas-vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
